Welcome back. Last time, we have discussed a very important topic of batch size. Today, we're going to continue on this and we are going further and discussing one another very important parameter, which we need to set, is the number of timesteps. But first of all, we're starting by importing the required packages. So, we are importing standard Numpy. We are importing Matplotlib. We import pandas, because by dealing with a pandas data frames, and we already here import Keras pre-processing sequence package. In the last session, we have said that we are going to select batch size of 64. Now, we will set to another important parameter which is number of epochs and number of timesteps. What is number of epochs? An epoch is a training ground. The more you train your neural network, the better it should get. Here, I have chosen Honda 20. In the later sessions and also in programming assignment, we are going to see how the number of epochs impacts the prediction quality. Here, the second parameter is number of timesteps. What is the meaning of this parameter, especially for LSTM? This is a very important setting. How do we predict? To understand this, imagine a rolling window. This window is divided in two parts with a red vertical line. This red vertical line is exactly in the middle of this window and this is the point of now. This is the point where we are at the moment. The 10 timesteps to the left is the past, and the 10 timesteps to the right is the future. So, the LSTM network is learning from the data, from the 10 timesteps which are allocated to the left, to predict the data which is located to the right of this red vertical line. And this sliding window, every time the LSTM has learned from 10 timesteps and has attempted to predict the 10 timesteps in the future, the whole sliding window slides one timestep to the right, and again, the whole procedure starts. It takes 10 timesteps to the left from now, from the past, it learns from it, it learns from this data, and then tries to predict what is going to be in the future, in the 10 timesteps in the future. And after it's completed, you move the sliding window again to the right one timesteps. This is called stright, this move. Normally, it's one timestep. You can control it but the default setting is always one. And now, we're selecting 10 timesteps. In this special data set, one timestep is meaning one day. So everyday, the crude oil prices are measured, and we have 10 timesteps in the past, where we learn how the prices were to predict 10 days, 10 timesteps in the future. It's nice, actually, if you look at it as a trader, for example, and you have this neural network, you can actually predict, if you have the history data and you have trained your neural network, you have now 10 days which are already recorded in the past, you can predict what is going to be with the prices 10 days in the future. And this is nice. So in the next session, we're going to discuss more in detail how we set the training set size with regard to the batch size. This is an important thing because we are working with a stateful LSTM. And therefore, the training set size must be entirely dividable by the batch size. Why so? This is because the batches are actually trainings units, so the neural network takes one batch of 64 observations. It will learn from it. It will update the parameters, as we said in a cell state and the hidden state, and these parameters will be transferred as initial state to the next batch. And the whole procedure starts again. So the trainings set consists of these batches. And therefore, you must set the training set size so you can divide by the batch size, meaning, major of such division must be zero. And we're going to define a method which provides us with the exact test set size given the data set and the batch size. This will be intensively discussed in the next session. Until then, enjoy and stay tuned. Bye.