1
00:00:00,000 --> 00:00:03,025
Hi. In this section,

2
00:00:03,025 --> 00:00:08,945
I am going to demonstrate some of the skills that you will need to execute Java code,

3
00:00:08,945 --> 00:00:16,610
particularly deep learning for J Neural network code in the data science experience.

4
00:00:16,610 --> 00:00:20,115
So, I've logged in to the data science experience,

5
00:00:20,115 --> 00:00:26,053
and the first thing I'm going to do is I'm going to create a new notebook.

6
00:00:26,053 --> 00:00:28,200
The notebook I'm going to create,

7
00:00:28,200 --> 00:00:33,774
I'm going to call Test DL4J.

8
00:00:33,774 --> 00:00:37,620
I'm going to use the Spark as a service,

9
00:00:37,620 --> 00:00:41,860
Python II, and create that notebook.

10
00:00:41,860 --> 00:00:44,635
Now, that the Kernel's started,

11
00:00:44,635 --> 00:00:49,535
let's go ahead and see what resources we already have available.

12
00:00:49,535 --> 00:00:55,335
So, I'm just going to run that LS command to list the contents of the current directory.

13
00:00:55,335 --> 00:00:57,880
The tools that we're going to be downloading,

14
00:00:57,880 --> 00:01:00,976
can be gathered from this URL.

15
00:01:00,976 --> 00:01:09,085
So, github.com/SkymindIO/dsx, for data science experience.

16
00:01:09,085 --> 00:01:15,085
In particular, we're going to go to the release,

17
00:01:15,085 --> 00:01:18,960
so that we can download these large files.

18
00:01:18,960 --> 00:01:29,245
This DL4J snapshot with dependencies.jar is all of the compiled classes in this repo.

19
00:01:29,245 --> 00:01:33,175
If you wanted to explore the Java,

20
00:01:33,175 --> 00:01:38,465
you could find that here in src/main/java/skymind/dsx.

21
00:01:38,465 --> 00:01:44,530
And there's the code for the classes that we're going to be executing.

22
00:01:44,530 --> 00:01:49,030
In this case, I'm going to execute the Iris-Classifier.

23
00:01:49,030 --> 00:01:53,020
And we'll see that the Iris-Classifier requires that

24
00:01:53,020 --> 00:01:57,165
we are able to read a file called iris.txt.

25
00:01:57,165 --> 00:01:58,970
So, in order to execute this,

26
00:01:58,970 --> 00:02:01,135
I will need two things.

27
00:02:01,135 --> 00:02:05,730
I will need the iris.txt file,

28
00:02:06,200 --> 00:02:10,805
that's up here in the top of the directory.

29
00:02:10,805 --> 00:02:14,430
And then I will need the compiled jar,

30
00:02:14,430 --> 00:02:19,028
that's in the release right there.

31
00:02:19,028 --> 00:02:21,075
So, let's grab that jar file,

32
00:02:21,075 --> 00:02:23,740
and let's grab that data file,

33
00:02:23,740 --> 00:02:30,600
iris.txt, and let's execute them in a data science experience.

34
00:02:30,600 --> 00:02:39,130
So, let's start by downloading the jar file.

35
00:02:39,130 --> 00:02:43,615
So, go to SkymindIO on GitHub,

36
00:02:43,615 --> 00:02:49,100
to the dsx project, there's one release.

37
00:02:49,100 --> 00:02:53,183
Right-click to get the URL.

38
00:02:53,183 --> 00:02:56,950
And then over in the data science experience,

39
00:02:56,950 --> 00:03:06,430
just execute bang wget to download that.

40
00:03:06,430 --> 00:03:13,351
We will also need the iris.txt file.

41
00:03:13,351 --> 00:03:15,090
And to locate that,

42
00:03:15,090 --> 00:03:18,348
it's in the top level of the project.

43
00:03:18,348 --> 00:03:21,980
There it is, iris.txt.

44
00:03:21,980 --> 00:03:24,995
You want to view the Raw,

45
00:03:24,995 --> 00:03:29,085
and then get that URL.

46
00:03:29,085 --> 00:03:31,790
And then over here,

47
00:03:31,790 --> 00:03:33,680
in the data science experience,

48
00:03:33,680 --> 00:03:40,230
wget with an exclamation point before it, and that URL.

49
00:03:41,120 --> 00:03:45,185
When those two commands have completed,

50
00:03:45,185 --> 00:03:51,005
we should see the jar file,

51
00:03:51,005 --> 00:04:03,130
and we should see iris.txt, and we do.

52
00:04:03,130 --> 00:04:08,910
So, we now have everything we need to execute it.

53
00:04:08,910 --> 00:04:16,675
One way to execute it is just use the local Java.

54
00:04:16,675 --> 00:04:19,225
If I type java version,

55
00:04:19,225 --> 00:04:22,150
bang java version, exclamation point java version,

56
00:04:22,150 --> 00:04:24,740
we see we have Java locally.

57
00:04:24,740 --> 00:04:27,940
And then, to execute that,

58
00:04:27,940 --> 00:04:34,980
I would just type "I need to specify the class path to include the

59
00:04:34,980 --> 00:04:45,755
jar," and then "I need to specify the class that I want to execute in that jar."

60
00:04:45,755 --> 00:04:50,440
And this is the class.

61
00:04:50,440 --> 00:04:55,170
So, if I execute that code,

62
00:04:55,190 --> 00:04:59,190
we will see the output of that.

63
00:04:59,190 --> 00:05:01,315
It's going to take a little bit of time,

64
00:05:01,315 --> 00:05:03,800
but we see it's building the model,

65
00:05:03,800 --> 00:05:11,530
and then it will go through many iterations on that model.

66
00:05:11,530 --> 00:05:14,190
As the model finishes,

67
00:05:14,190 --> 00:05:18,460
I will see it goes through thousand iterations.

68
00:05:18,460 --> 00:05:23,110
We see the score is generally decreasing,

69
00:05:23,110 --> 00:05:27,485
getting towards zero, meaning the model's getting better at making predictions.

70
00:05:27,485 --> 00:05:29,635
And when the model's done,

71
00:05:29,635 --> 00:05:33,980
we operate an evaluation of the true table,

72
00:05:33,980 --> 00:05:35,630
how accurate we were.

73
00:05:35,630 --> 00:05:38,840
So, Class zero, we got correct.

74
00:05:38,840 --> 00:05:42,170
Class one, we got correct 22 times.

75
00:05:42,170 --> 00:05:45,485
Class one, we got incorrect two times.

76
00:05:45,485 --> 00:05:49,995
And class two, we got correct 10 times.

77
00:05:49,995 --> 00:05:57,950
So, there you have executing the model using the local Java.

78
00:05:57,950 --> 00:06:07,410
I could also submit the jar and my data file to Spark.

79
00:06:07,410 --> 00:06:10,485
I would do that using this command.

80
00:06:10,485 --> 00:06:13,850
So, Spark homes an environmental variable that

81
00:06:13,850 --> 00:06:17,050
points to the location of the spark-submit executable.

82
00:06:17,050 --> 00:06:18,515
So, I start with that, and once again,

83
00:06:18,515 --> 00:06:21,630
I start to command with an exclamation point.

84
00:06:21,630 --> 00:06:25,955
Spark-submit allows you to specify which class you're going to execute,

85
00:06:25,955 --> 00:06:28,880
so I specify that here.

86
00:06:28,880 --> 00:06:32,345
When I'm submitting a job to Spark,

87
00:06:32,345 --> 00:06:36,665
I need to specify the master, and once again,

88
00:06:36,665 --> 00:06:41,995
the data science experience has an environmental variable set named

89
00:06:41,995 --> 00:06:50,600
Master that points to the URL of the current Spark Master.

90
00:06:50,600 --> 00:06:57,860
We need to ship it the file iris.txt and we can do that using the files command.

91
00:06:57,860 --> 00:07:01,410
And then, the last argument,

92
00:07:01,410 --> 00:07:05,645
we need to include the jar.

93
00:07:05,645 --> 00:07:07,360
So, this command will say,

94
00:07:07,360 --> 00:07:13,885
"Ship this jar up to this Spark master, execute this class."

95
00:07:13,885 --> 00:07:18,055
That class will be looking for this file, iris.txt,

96
00:07:18,055 --> 00:07:20,955
and that command, --files,

97
00:07:20,955 --> 00:07:24,220
ships it up and makes it available to each worker.

98
00:07:24,220 --> 00:07:28,640
Note that here, we're really just using Spark as an execution environment.

99
00:07:28,640 --> 00:07:31,100
We're not building a Spark context,

100
00:07:31,100 --> 00:07:33,815
doing fully distributed work.

101
00:07:33,815 --> 00:07:37,070
We're just shipping a single class to execute once,

102
00:07:37,070 --> 00:07:40,017
so we're not taking full advantage of Spark,

103
00:07:40,017 --> 00:07:44,480
but we are executing our code in Spark.

104
00:07:44,480 --> 00:07:46,805
And there you see the output,

105
00:07:46,805 --> 00:07:49,230
as it begins to run.

106
00:07:49,230 --> 00:07:56,170
As that code finishes, you'll see the same thing.

107
00:07:56,170 --> 00:07:59,575
You'll see the score at the final iteration,

108
00:07:59,575 --> 00:08:06,165
you'll see the truth table and there you have it.

109
00:08:06,165 --> 00:08:11,440
So, we can execute our Java code in two ways.

110
00:08:11,440 --> 00:08:15,100
In both cases, we need to build a Hoover Jar,

111
00:08:15,100 --> 00:08:16,345
a jar with dependencies,

112
00:08:16,345 --> 00:08:21,205
ship the jar and any needed text files into the data science experience.

113
00:08:21,205 --> 00:08:24,235
Once we have that content in the data science experience,

114
00:08:24,235 --> 00:08:26,935
we can either execute Java,

115
00:08:26,935 --> 00:08:29,575
ship it to class path of the jar,

116
00:08:29,575 --> 00:08:31,990
specify the class you want to execute and execute

117
00:08:31,990 --> 00:08:34,555
it locally in the data science experience,

118
00:08:34,555 --> 00:08:38,365
or we can ship the jar and specify the class

119
00:08:38,365 --> 00:08:43,020
to execute when we ship that to spark-submit. Thank you.