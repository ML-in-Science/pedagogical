In this video, we're going to introduce sequential models with Keras. In Keras, you have essentially two types of models available. One is called Sequential and you use it to define sequential models, meaning you simply stack layers one by one, sequentially. And this is the focus of this lecture. There's another model available in Keras that is mainly used for non-sequential models, and it goes by the name Model. Those more general models use a functional API. We're going to introduce this API later on. Okay, let's take a step back. Regardless of which model you define, the core abstraction to each Keras model is the notion of a layer. So, each model consists of a bunch of layers. In a sequential model, we stack layers sequentially. So, each layer has unique input and output, and those inputs and outputs then also come with a unique input shape and output shape. If you want to retrieve the weights a layer has, you can simply call get weights on layer and retrieve all those weights as as a list of numpy arrays. If you want to set weights, that's also possible by simply calling set weights with a given list of numpy arrays weights. Also, each layer has its defining configuration which you can get by calling get config on a layer. To build a sequential model, you have to carry out a few steps. First, we instantiate a sequential model, then we add layers to it one by one. Afterwards, we need to compile a model with a mandatory loss function and a mandatory optimizer, and if we like, also with optional evaluation metrics such as accuracy. Afterwards, we fit our model to training data that we provide. And after that, well, it really depends what you want to do. Most of the time we evaluate our model but, sometimes you also want to maybe serialize or persist model or deploy it somewhere or start a new experiment altogether. It really depends on your use case. Essentially, this is the list of steps that you have to carry out each time when you define a Keras model. All right. Let's have a closer look at the compiling step of a model. As we said before, we have to carry out essentially two steps. We have to provide loss function and we have to provide an optimizer. Defining a loss function can be done in two ways. First, we can import a specific loss function, in this case, mean squared error, from the Keras losses module. This is the recommended way. If you compile a model with this, you simply specify the loss keyword here, we set it to mean squared error, and we left out the optimizer for now. The second option is simply call the respective loss function by name. That is, you provide a string that stands for the loss function. This is somewhat error prone, because if you have a typo in that, it simply won't work. So, we really recommend the first way. Okay. To defend an optimizer again, there's two way of doing this. The first and preferred way for us is you import a specific optimizer from the Keras optimizers sub module. In this case, we import stochastic gradient descent, SGD. Then, we instantiate an SGD object by specifying a few parameters. So, for instance here, we set the learning rate to 0.01 and also put decay factor that will decrease the learning rate after each parameter update and we also set momentum parameter to 0.9 for this particular optimizer. Then, we can compile our model with this particular instance SGD. The second option is, you simply pass a string, pretty much the same way as we did for losses, but in this case, it's crucial to see that if you pass SGD as a string, you cannot specify any specific parameters but, all the default parameters would just be valid. All right. Once you're done with compiling your model, you simply fit it to training features and labels, and you also always have to specify a batch size, the number of epochs you want to train, and optionally you can also specify validation data. Afterwards, you can evaluate your model or simply predict on new features, as you like. Okay. So, this was a high level overview of Keras sequential models and in the next lecture, we're going to talk specifically about how to build Feedforward neural networks and tackle a contentious case.