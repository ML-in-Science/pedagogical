Now, let's actually see how we can scale a neural network on Apache Spark using SystemML. So, we're using the import functionality of SystemML, which can read a Keras Model and create the DMA for SystemML out of it. This is completely transparent, so you won't notice that. The only thing is that you will notice that the training is far faster. So, let's run some imports. And please ignore this little warning and reload the data as before. And we'll reshape it, and scale it, again as before. Then again, we set some constants, like 10 steps dimension in sentence. And then again, we define a neural network using a Sequential Keras Model. We add one LSTM layer with 50 neurons, and you define the input shape and the input dimensions. And then, we add an output layer, which is a dense layer. We compile the model. We use mean square of errors as costs function, we use momentum based stochastic gradient descent optimizer. Now, it gets interesting. So, we import the keras2DML class, we set constant for epochs and batch size, and to compute the number of iterations. So now, this is the most interesting part. So, we instantiate this keras2DML class. The first parameter is the Spark session. This is the way to talk to the Apache Spark cluster in the background which is part of this system. Second parameter is the Keras model. Then input_shape already know what it is. Then we set the batch size, max iterations, and every 10 iterations, we display the loss. Since we are predicting a continuous value, we set perform_one_hot_encoding to false. So, let's create this model, and then we can train it. Here, we see that the loss is going down. But now, this model is trained on an Apache Spark cluster using Apache Spark workers. So you can parallelize this model to any number of workers you need. You even can add or remove workers during runtime. And you can use any Apache Spark installation whether it is in a cloud, on prem, or on your local machine. So this is done after 30 seconds since this is only a tiny example and you see here that two Spark workers have been used. The reason for this is that in the free version of data and experience, you get only two Spark workers. So now, let's see what keras2DML actually is doing. So we set debug to true then we train again. And the first output is that DML code which is generated and then executed by the system in my runtime. So you see that all the newer network libraries are sourced. Here, the first LSTM layer is initialized with the batch size, the number of input neurons and a number of output neurons. Input neurons is three because our input data is three-dimensional, and in Keras, we defined that the LSTM layer should have 50 internal neurons. Followed by that, we have a fully connected dense output layer with 50 input neurons and 30 output neurons. So 30 output neurons are needed because we are predicting 10 future timesteps and we have three dimensions of data. So then, the stochastic gradient descent optimizer's initialized. And here, we are entering the gradient descent group. That LSTM layer, for example, is computed backwards. This means all the computations are taking place in reverse order and, of course, we are calculating on the first derivative of the function. This backward function returns the gradient. And then the stochastic gradient descent optimizer is used for computing the updates of the weights. This might look a bit low level to you, and it is, but it's at the same level than Tensorflow. So tensorflow and SystemML are some sort of low level linear algebra execution environments. But the cool thing is, here, you can work with Keras and you see what low level DML code the library is actually producing, and if you like, you can learn from it and also tweak it. So, I hope this convinced you to have a closer look and very cool thing is that the DML code is running in an optimized fashion, taking statistics about data set sizes into account. Thanks a lot.