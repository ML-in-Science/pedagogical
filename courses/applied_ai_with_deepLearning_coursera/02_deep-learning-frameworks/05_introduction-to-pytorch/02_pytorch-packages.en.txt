Welcome back. In the last session, we have briefly discussed how to install PyTorch. Today we're going to look at the most important PyTorch libraries. First of all, this is the torch library, which is actually the Tensor library of PyTorch. This library is very similar to NumPy. The second one is the torch-autograd library. This is at tape-based automatic differentiation library. What is the meaning of this tape-based and automatic? We're going to see in our next sessions. Here I have torch.nn. This is a neural network library. We are not going to build up a neural network in this introductory sessions. But it's important to know that this library is actually the most important if you would like to build neural network. And here the last one is the torch optim library. This is a torch optimization library which contains all those famous algorithms, optimization algorithms like SGD, Stochastic Gradient Descent, RMSProp, Adam, and so on which we all know from in other frameworks like Keras, and TensorFlow, and so on. So just execute the cell. And it says here a manual seed. And I see everything is fine executed. I just wanted to mention that all those introductory sessions, I'm basing actually on official Pytorch documentation. But I will try to give you a little bit more insight in what is the meaning of, especially if we are speaking about high dimensional arrays, and we're talking about autograd and so on, it could be a little bit confusing. So with this introductory session, I think everything will be fine. And stay tuned and see you in the next session. Bye bye.